{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Custom modules and functions\n",
    "import capstone.portfolio.optimize as opt\n",
    "from capstone.portfolio.prune import prune_recommended_portfolios\n",
    "from capstone.model_selection import overunder_error\n",
    "from capstone.utils import read_file, get_sectors\n",
    "\n",
    "# Machine learning and modeling tools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Progress bar for loops\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Custom modules and functions\n",
    "import capstone.portfolio.optimize as opt\n",
    "from capstone.portfolio.prune import prune_recommended_portfolios\n",
    "from capstone.model_selection import overunder_error\n",
    "from capstone.utils import read_file, get_sectors\n",
    "\n",
    "# Machine learning and modeling tools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Progress bar for loops\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "class Burray:\n",
    "\n",
    "    def __init__(self, forecast=126, cv=2):\n",
    "        self.recommended_sector = None\n",
    "        self.recommended_stocks = None\n",
    "        self.maximum_sharpe_portfolio = None\n",
    "        self.minimum_variance_portfolio = None\n",
    "        self.risk_parity_portfolio = None\n",
    "        self.best_model = None\n",
    "        self.top_sectors = None\n",
    "        self.mean_predicted_returns = None\n",
    "\n",
    "        self._forecast = forecast\n",
    "        self._cv = cv\n",
    "        self._tscv = TimeSeriesSplit(self._cv)\n",
    "        self._pca = make_pipeline(StandardScaler(), PCA(n_components=.8, random_state=42))\n",
    "        self._models = {\n",
    "            'ElasticNet': make_pipeline(StandardScaler(), ElasticNet(alpha=1, l1_ratio=0.5, random_state=42)),\n",
    "            'SVR': make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1, gamma='auto')),\n",
    "            'RandomForest': RandomForestRegressor(n_estimators=100, max_depth=3, random_state=42),\n",
    "            'GradientBoost': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "            'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "        }\n",
    "    \n",
    "    def run(self):\n",
    "        self._get_data()\n",
    "        self._pca_transform()\n",
    "        self._get_best_model()\n",
    "        self._recommend_sector()\n",
    "        self._recommend_constituents()\n",
    "        self._get_optimal_allocations()\n",
    "        print(\"Recommendation complete.\")\n",
    "\n",
    "    def _get_data(self):\n",
    "        self._master_data = read_file(\"master_df\", index_col=\"Date\")\n",
    "        self._log_returns = read_file(\"snp_log_returns\", index_col=\"Date\")\n",
    "        self._stocks_by_sector =read_file(\"stocks_by_sector\", index_col=0)\n",
    "        self._sectors = get_sectors()\n",
    "        self._y_all = self._master_data[self._sectors]\n",
    "        self._X_all = self._master_data[\n",
    "            self._master_data.columns[\n",
    "                ~self._master_data.columns.isin(self._y_all.columns)\n",
    "            ]\n",
    "        ]\n",
    "    \n",
    "    def _pca_transform(self):\n",
    "        self._X_pca = pd.DataFrame(\n",
    "            self._pca.fit_transform(self._X_all), \n",
    "            index=self._X_all.index\n",
    "        )\n",
    "        self._X_pca.columns = [f\"PC{i+1}\" for i in self._X_pca.columns]\n",
    "\n",
    "    def _get_best_model(self):\n",
    "        self._X_pca_shifted = self._X_pca.shift(self._forecast).dropna()\n",
    "        self._X_pca_recent = X = self._X_pca_shifted.iloc[-self._forecast*2:]\n",
    "        self._y_recent = self._y_all.iloc[-self._forecast*2:]\n",
    "        ouls = {model: pd.DataFrame(index=self._sectors, columns=[\"MEAN_OUL\"]) for model in self._models.keys()}\n",
    "        for sector in tqdm(self._sectors):\n",
    "            y = self._y_recent[sector]\n",
    "            for name, model in self._models.items():\n",
    "                cv_oul = []\n",
    "                for train_idx, test_idx in self._tscv.split(self._X_pca_recent):\n",
    "                    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "                    y_train, y_test = y[train_idx], y[test_idx]\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_hat_val = model.predict(X_test)\n",
    "                    cv_oul.append(overunder_error(y_test, y_hat_val))\n",
    "                oul_mean = np.mean(cv_oul)\n",
    "                ouls[name].loc[sector, \"MEAN_OUL\"] = oul_mean\n",
    "        mean_ouls = pd.DataFrame({model: oul.mean() for model, oul in ouls.items()})\n",
    "        self.best_model = mean_ouls.idxmin(axis=1)[0]\n",
    "    \n",
    "    def _recommend_sector(self):\n",
    "        future_start = self._y_all.index.max() + pd.DateOffset(1)\n",
    "        future_end = future_start + pd.DateOffset(self._forecast - 1)\n",
    "        future_dates = pd.date_range(future_start, future_end)\n",
    "        self._X_train = self._X_pca[-self._forecast*2:-self._forecast]\n",
    "        self._y_train = self._y_recent[-self._forecast:]\n",
    "        self._X_test = self._X_pca[-self._forecast:]\n",
    "        self._models[self.best_model].fit(self._X_train, self._y_train)\n",
    "        predicted_returns = pd.DataFrame(self._models[self.best_model].predict(self._X_test), columns=self._sectors, index=future_dates)\n",
    "        self.top_sectors = predicted_returns.cumsum().iloc[-1].sort_values(ascending=False)[:5]\n",
    "        self.mean_predicted_returns = predicted_returns.mean()\n",
    "        self.recommended_sector = self.mean_predicted_returns.idxmax()\n",
    "\n",
    "    def _recommend_constituents(self):\n",
    "        available_stocks = self._stocks_by_sector[self._stocks_by_sector[\"GICS Sector\"] == self.recommended_sector][\"Symbol\"].to_list()\n",
    "        self.recommended_stocks = [stock for stock in available_stocks if stock in self._log_returns.columns]\n",
    "    \n",
    "    def _get_optimal_allocations(self):\n",
    "        weights = np.array([1/len(self.recommended_stocks)] * len(self.recommended_stocks))\n",
    "        recent_returns = self._log_returns[-self._forecast:][self.recommended_stocks]\n",
    "        max_sharpe_weights = opt.max_sharpe_opt(weights, recent_returns)[0]\n",
    "        min_var_weights = opt.min_var_opt(weights, recent_returns)[0]\n",
    "        risk_parity_weights = opt.risk_parity_opt(weights, recent_returns)[0]\n",
    "        maximum_sharpe_portfolio = pd.Series(max_sharpe_weights, index=self.recommended_stocks)\n",
    "        minimum_variance_portfolio = pd.Series(min_var_weights, index=self.recommended_stocks)\n",
    "        risk_parity_portfolio = pd.Series(risk_parity_weights, index=self.recommended_stocks)\n",
    "        self.maximum_sharpe_portfolio, self.minimum_variance_portfolio, self.risk_parity_portfolio = \\\n",
    "            prune_recommended_portfolios(\n",
    "                maximum_sharpe_portfolio, minimum_variance_portfolio, risk_parity_portfolio\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e3c6cc5d904476a5218db1802e4b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation complete.\n"
     ]
    }
   ],
   "source": [
    "burray = Burray()\n",
    "burray.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AKAM    0.021723\n",
       "AAPL    0.042030\n",
       "CSCO    0.040485\n",
       "CTSH    0.010551\n",
       "IBM     0.384053\n",
       "MSFT    0.053954\n",
       "MSI     0.065286\n",
       "ROP     0.205191\n",
       "CRM     0.036814\n",
       "VRSN    0.139913\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burray.minimum_variance_portfolio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
