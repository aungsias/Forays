{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Custom modules and functions\n",
    "from capstone.model_selection import overunder_error, arimax_cross_val_score\n",
    "from capstone.utils import read_file, get_sectors, set_plot_style\n",
    "\n",
    "# SARIMAX model from statsmodels\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Machine learning and modeling tools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Progress bar for loops\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ignore convergence warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "# Set visualization style and adjust plot settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"lines.linewidth\"] = 1\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in files\n",
    "sectors = get_sectors()\n",
    "df = read_file(\"master_df\", index_col=0)\n",
    "\n",
    "targets = df[sectors]\n",
    "features = df[df.columns[~df.columns.isin(sectors)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4e8dc0a5f84362a3aeec4d779b430c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the forecast horizon in terms of trading days per year\n",
    "trading_days = 252\n",
    "forecast = int(trading_days / 2)\n",
    "\n",
    "# Shift the features to match the forecast horizon, and drop any missing values\n",
    "X_shifted = features.shift(forecast).dropna()\n",
    "\n",
    "# Align the target data with the shifted features\n",
    "y_all = targets.reindex(X_shifted.index)\n",
    "\n",
    "# Create a pipeline for standardizing and applying PCA\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(n_components=.8, random_state=42))\n",
    "\n",
    "# Define the ARIMAX orders for ARIMA and seasonal components\n",
    "order = (1, 0, 1) # Returns are usually stationary, so no differencing applied\n",
    "\n",
    "# Initialize empty DataFrames to store predictions and over-under loss scores\n",
    "arimax_preds = pd.DataFrame()\n",
    "arimax_ouls = pd.DataFrame()\n",
    "\n",
    "# Loop through each sector\n",
    "for sector in tqdm(sectors):\n",
    "\n",
    "    # Extract the target variable for the current sector\n",
    "    y = y_all[sector]\n",
    "\n",
    "    # Loop through the data with a window equal to the forecast horizon\n",
    "    for i in range(forecast, len(y), forecast):\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test = X_shifted.iloc[i-forecast:i], X_shifted.iloc[i:i+forecast]\n",
    "        y_train, y_test = y[i-forecast:i], y[i:i+forecast]\n",
    "\n",
    "        # Apply PCA to the training and testing feature sets\n",
    "        X_train_pca = pca_pipe.fit_transform(X_train)\n",
    "        X_test_pca = pca_pipe.transform(X_test)\n",
    "\n",
    "        # Perform time-series cross-validation and calculate the mean over-under loss\n",
    "        mean_oul = np.mean(\n",
    "            arimax_cross_val_score(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                order=order,\n",
    "                pca=pca_pipe,\n",
    "                cv=2,\n",
    "                scorer=overunder_error,\n",
    "                overpred_penalty=2,\n",
    "                underpred_penalty=0\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Store the mean over-under loss score\n",
    "        arimax_ouls.loc[X_test.index.min(), sector] = mean_oul\n",
    "\n",
    "        # Fit the ARIMAX model to the training data\n",
    "        model = SARIMAX(y_train.values, X_train_pca, order=order).fit()\n",
    "\n",
    "        # Generate forecasts for the testing data\n",
    "        forecast_results = model.get_forecast(steps=len(X_test_pca), exog=X_test_pca)\n",
    "        y_hat = forecast_results.predicted_mean\n",
    "\n",
    "        # Store the mean forecasted value\n",
    "        arimax_preds.loc[X_test.index.min(), sector] = np.mean(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arimax_mean_ouls = pd.DataFrame(arimax_ouls.mean(axis=1), columns=[\"ARIMAX\"])\n",
    "arimax_best_sectors = pd.DataFrame(arimax_preds.idxmax(axis=1), columns=[\"ARIMAX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arimax_mean_ouls.to_csv(\"data/arimax_mean_ouls.csv\")\n",
    "arimax_best_sectors.to_csv(\"data/arimax_best_sectors.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
