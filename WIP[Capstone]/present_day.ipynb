{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Custom modules and functions\n",
    "import capstone.portfolio.optimize as opt\n",
    "from capstone.portfolio.prune import prune_recommended_portfolios\n",
    "from capstone.model_selection import overunder_error\n",
    "from capstone.utils import read_file, get_sectors\n",
    "\n",
    "# Machine learning and modeling tools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Progress bar for loops\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set visualization style and adjust plot settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"lines.linewidth\"] = 1\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "df = read_file(\"master_df\", index_col=\"Date\")\n",
    "snp_log_returns = read_file(\"snp_log_returns\", index_col=\"Date\")\n",
    "stocks_by_sector = read_file(\"stocks_by_sector\", index_col=0)\n",
    "sectors = get_sectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4230, 109), (4230, 11))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the combined dataframe into targets (sector average returns) and features\n",
    "y_all = df[sectors]\n",
    "X_all = df[df.columns[~df.columns.isin(y_all.columns)]]\n",
    "\n",
    "X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "      <th>PC19</th>\n",
       "      <th>PC20</th>\n",
       "      <th>PC21</th>\n",
       "      <th>PC22</th>\n",
       "      <th>PC23</th>\n",
       "      <th>PC24</th>\n",
       "      <th>PC25</th>\n",
       "      <th>PC26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-09-05</th>\n",
       "      <td>1.572267</td>\n",
       "      <td>2.251625</td>\n",
       "      <td>-0.166538</td>\n",
       "      <td>0.577534</td>\n",
       "      <td>1.593571</td>\n",
       "      <td>0.727317</td>\n",
       "      <td>-1.045755</td>\n",
       "      <td>1.717850</td>\n",
       "      <td>-1.269176</td>\n",
       "      <td>0.550307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728028</td>\n",
       "      <td>0.924053</td>\n",
       "      <td>-0.644267</td>\n",
       "      <td>1.030472</td>\n",
       "      <td>-0.345593</td>\n",
       "      <td>-0.441153</td>\n",
       "      <td>1.619234</td>\n",
       "      <td>0.391941</td>\n",
       "      <td>-0.633839</td>\n",
       "      <td>-0.080373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-06</th>\n",
       "      <td>0.149746</td>\n",
       "      <td>4.029874</td>\n",
       "      <td>-2.027692</td>\n",
       "      <td>-0.273766</td>\n",
       "      <td>2.112711</td>\n",
       "      <td>-1.341697</td>\n",
       "      <td>-1.386221</td>\n",
       "      <td>1.648393</td>\n",
       "      <td>-1.603688</td>\n",
       "      <td>0.135565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.506765</td>\n",
       "      <td>-0.260769</td>\n",
       "      <td>-0.553688</td>\n",
       "      <td>0.134524</td>\n",
       "      <td>-0.372484</td>\n",
       "      <td>-0.691424</td>\n",
       "      <td>1.085630</td>\n",
       "      <td>1.428667</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>-0.880374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07</th>\n",
       "      <td>-4.043578</td>\n",
       "      <td>-0.026559</td>\n",
       "      <td>1.689399</td>\n",
       "      <td>-1.105289</td>\n",
       "      <td>2.137391</td>\n",
       "      <td>1.417627</td>\n",
       "      <td>-1.899516</td>\n",
       "      <td>1.022726</td>\n",
       "      <td>-0.914299</td>\n",
       "      <td>0.664205</td>\n",
       "      <td>...</td>\n",
       "      <td>1.818843</td>\n",
       "      <td>-0.777557</td>\n",
       "      <td>0.211620</td>\n",
       "      <td>-1.885068</td>\n",
       "      <td>-0.761534</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.876800</td>\n",
       "      <td>0.946822</td>\n",
       "      <td>0.448153</td>\n",
       "      <td>-0.360191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-08</th>\n",
       "      <td>-3.933137</td>\n",
       "      <td>6.109104</td>\n",
       "      <td>0.671842</td>\n",
       "      <td>0.143338</td>\n",
       "      <td>-0.723764</td>\n",
       "      <td>0.634047</td>\n",
       "      <td>-2.434709</td>\n",
       "      <td>-0.209488</td>\n",
       "      <td>-1.234175</td>\n",
       "      <td>-0.387969</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.609450</td>\n",
       "      <td>-0.543206</td>\n",
       "      <td>0.077936</td>\n",
       "      <td>0.335162</td>\n",
       "      <td>-1.065407</td>\n",
       "      <td>0.129781</td>\n",
       "      <td>0.520862</td>\n",
       "      <td>-0.116500</td>\n",
       "      <td>0.964564</td>\n",
       "      <td>0.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-11</th>\n",
       "      <td>-2.804780</td>\n",
       "      <td>6.085291</td>\n",
       "      <td>-0.323564</td>\n",
       "      <td>0.342325</td>\n",
       "      <td>-2.640603</td>\n",
       "      <td>1.833748</td>\n",
       "      <td>-0.759626</td>\n",
       "      <td>0.070136</td>\n",
       "      <td>-2.033351</td>\n",
       "      <td>-0.796932</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.936066</td>\n",
       "      <td>2.195284</td>\n",
       "      <td>-0.697539</td>\n",
       "      <td>-0.705440</td>\n",
       "      <td>0.354325</td>\n",
       "      <td>-1.076233</td>\n",
       "      <td>-0.243180</td>\n",
       "      <td>-0.156890</td>\n",
       "      <td>1.308446</td>\n",
       "      <td>-0.409407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
       "Date                                                                     \n",
       "2023-09-05  1.572267  2.251625 -0.166538  0.577534  1.593571  0.727317   \n",
       "2023-09-06  0.149746  4.029874 -2.027692 -0.273766  2.112711 -1.341697   \n",
       "2023-09-07 -4.043578 -0.026559  1.689399 -1.105289  2.137391  1.417627   \n",
       "2023-09-08 -3.933137  6.109104  0.671842  0.143338 -0.723764  0.634047   \n",
       "2023-09-11 -2.804780  6.085291 -0.323564  0.342325 -2.640603  1.833748   \n",
       "\n",
       "                 PC7       PC8       PC9      PC10  ...      PC17      PC18  \\\n",
       "Date                                                ...                       \n",
       "2023-09-05 -1.045755  1.717850 -1.269176  0.550307  ... -0.728028  0.924053   \n",
       "2023-09-06 -1.386221  1.648393 -1.603688  0.135565  ... -0.506765 -0.260769   \n",
       "2023-09-07 -1.899516  1.022726 -0.914299  0.664205  ...  1.818843 -0.777557   \n",
       "2023-09-08 -2.434709 -0.209488 -1.234175 -0.387969  ... -1.609450 -0.543206   \n",
       "2023-09-11 -0.759626  0.070136 -2.033351 -0.796932  ... -2.936066  2.195284   \n",
       "\n",
       "                PC19      PC20      PC21      PC22      PC23      PC24  \\\n",
       "Date                                                                     \n",
       "2023-09-05 -0.644267  1.030472 -0.345593 -0.441153  1.619234  0.391941   \n",
       "2023-09-06 -0.553688  0.134524 -0.372484 -0.691424  1.085630  1.428667   \n",
       "2023-09-07  0.211620 -1.885068 -0.761534  0.386206  0.876800  0.946822   \n",
       "2023-09-08  0.077936  0.335162 -1.065407  0.129781  0.520862 -0.116500   \n",
       "2023-09-11 -0.697539 -0.705440  0.354325 -1.076233 -0.243180 -0.156890   \n",
       "\n",
       "                PC25      PC26  \n",
       "Date                            \n",
       "2023-09-05 -0.633839 -0.080373  \n",
       "2023-09-06  0.183519 -0.880374  \n",
       "2023-09-07  0.448153 -0.360191  \n",
       "2023-09-08  0.964564  0.432200  \n",
       "2023-09-11  1.308446 -0.409407  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a pipeline for PCA with standard scaling\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(n_components=.8, random_state=42))\n",
    "\n",
    "# Store pca-transformed features in a dataframe\n",
    "X_pca = pd.DataFrame(\n",
    "    pca_pipe.fit_transform(X_all), \n",
    "    index=X_all.index\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "X_pca.columns = [f\"PC{i+1}\" for i in X_pca.columns]\n",
    "\n",
    "X_pca.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    # ElasticNet combines L1 and L2 regularization, suitable for feature selection and dealing with multicollinearity.\n",
    "    'ElasticNet': make_pipeline(StandardScaler(), ElasticNet(alpha=1, l1_ratio=0.5, random_state=42)),\n",
    "    \n",
    "    # Support Vector Regressor (SVR) with an RBF kernel can capture non-linear relationships in stock returns.\n",
    "    'SVR': make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1, gamma='auto')),\n",
    "    \n",
    "    # RandomForestRegressor is an ensemble method that can capture complex relationships and feature importance.\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, max_depth=3, random_state=42),\n",
    "    \n",
    "    # GradientBoostingRegressor is another ensemble method suitable for capturing non-linear relationships and trends.\n",
    "    'GradientBoost': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \n",
    "    # XGBoostRegressor is an optimized gradient boosting algorithm known for its speed and performance.\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet\n"
     ]
    }
   ],
   "source": [
    "# Set the forecast horizon to 126 days (approx. 1/2 trading year)\n",
    "forecast = 126\n",
    "\n",
    "# Initialize TimeSeriesSplit object for cross-validation with 2 splits\n",
    "cv = 2\n",
    "tscv = TimeSeriesSplit(cv)\n",
    "\n",
    "# Shift the PCA-transformed features to align with the forecast horizon and remove NA rows\n",
    "X_pca_shifted = X_pca.shift(forecast).dropna()\n",
    "\n",
    "# Select the most recent subset of data, doubled to the size of the forecast window\n",
    "X_pca_recent = X = X_pca_shifted.iloc[-forecast*2:]\n",
    "y_recent = y_all.iloc[-forecast*2:]\n",
    "\n",
    "# Initialize dictionary to store the Mean Over-Under Loss (MEAN_OUL) for each model and sector\n",
    "ouls = {model: pd.DataFrame(index=sectors, columns=[\"MEAN_OUL\"]) for model in models.keys()}\n",
    "\n",
    "# Loop through each sector to train and validate models\n",
    "for sector in sectors:\n",
    "    y = y_recent[sector]\n",
    "\n",
    "    # Loop through each machine learning model\n",
    "    for name, model in models.items():\n",
    "        cv_oul = []  # List to store cross-validation Over-Under Loss for current model\n",
    "\n",
    "        # Time-series cross-validation\n",
    "        for train_idx, test_idx in tscv.split(X_pca_recent):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            # Fit the model on the training set and predict on the test set\n",
    "            model.fit(X_train, y_train)\n",
    "            y_hat_val = model.predict(X_test)\n",
    "\n",
    "            # Calculate Over-Under Loss and append to cv_oul list\n",
    "            cv_oul.append(overunder_error(y_test, y_hat_val))\n",
    "\n",
    "        # Calculate mean Over-Under Loss across all cross-validation runs\n",
    "        oul_mean = np.mean(cv_oul)\n",
    "        ouls[name].loc[sector, \"MEAN_OUL\"] = oul_mean\n",
    "\n",
    "# Compute the mean Over-Under Loss for each model across all sectors\n",
    "mean_ouls = pd.DataFrame({model: oul.mean() for model, oul in ouls.items()})\n",
    "\n",
    "# Identify the best model based on the lowest mean Over-Under Loss\n",
    "best_model = mean_ouls.idxmin(axis=1)[0]\n",
    "\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFORMATION_TECHNOLOGY    0.160892\n",
       "ENERGY                    0.146670\n",
       "CONSUMER_DISCRETIONARY    0.089027\n",
       "COMMUNICATION_SERVICES    0.088246\n",
       "INDUSTRIALS               0.064115\n",
       "Name: 2024-01-15 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the date immediately following the last date in the existing target data\n",
    "future_start = y.index.max() + pd.DateOffset(1)\n",
    "\n",
    "# Calculate the final date for the forecast period\n",
    "future_end = future_start + pd.DateOffset(forecast - 1)\n",
    "\n",
    "# Generate a date range covering the entire forecast period\n",
    "future_dates = pd.date_range(future_start, future_end)\n",
    "\n",
    "# Use the last 2*forecast rows of the PCA-transformed features as training data\n",
    "X_train = X_pca[-forecast*2:-forecast]\n",
    "\n",
    "# Use the last forecast rows of the recent target data as training data\n",
    "y_train = y_recent[-forecast:]\n",
    "\n",
    "# Use the last forecast rows of the PCA-transformed features as test data\n",
    "X_test = X_pca[-forecast:]\n",
    "\n",
    "# Fit the best-performing model to the training data\n",
    "models[best_model].fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict future returns\n",
    "predicted_returns = pd.DataFrame(models[best_model].predict(X_test), columns=sectors, index=future_dates)\n",
    "\n",
    "# Inspect the cumulative log returns of each sector by the end of the forecast period\n",
    "predicted_returns.cumsum().iloc[-1].sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMATION_TECHNOLOGY\n"
     ]
    }
   ],
   "source": [
    "# Compute mean predicted returns of each sector\n",
    "mean_predicted_returns = predicted_returns.mean()\n",
    "\n",
    "# Retrieve the sector with the highest predicted returns\n",
    "recommended_sector = mean_predicted_returns.idxmax()\n",
    "\n",
    "print(recommended_sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stocks belonging to the recommended sector\n",
    "available_stocks = stocks_by_sector[stocks_by_sector[\"GICS Sector\"] == recommended_sector][\"Symbol\"].to_list()\n",
    "\n",
    "# Filter those stocks to only include those present in the S&P 500 log returns data\n",
    "recommended_stocks = [stock for stock in available_stocks if stock in snp_log_returns.columns]\n",
    "\n",
    "# Initialize an equal-weight portfolio for the recommended stocks\n",
    "weights = np.array([1/len(recommended_stocks)] * len(recommended_stocks))\n",
    "\n",
    "# Get the recent log returns for the recommended stocks\n",
    "recent_returns = snp_log_returns[-forecast:][recommended_stocks]\n",
    "\n",
    "# Calculate the optimal weights for a Maximum Sharpe ratio portfolio using recent returns\n",
    "max_sharpe_weights = opt.max_sharpe_opt(weights, recent_returns)[0]\n",
    "\n",
    "# Calculate the optimal weights for a Minimum Variance portfolio using recent returns\n",
    "min_var_weights = opt.min_var_opt(weights, recent_returns)[0]\n",
    "\n",
    "# Calculate the optimal weights for a Risk Parity portfolio using recent returns\n",
    "risk_parity_weights = opt.risk_parity_opt(weights, recent_returns)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas Series for each portfolio type (Max Sharpe, Min Variance, Risk Parity)\n",
    "# The Series have stock symbols as the index and respective weights as values.\n",
    "max_sharpe_portfolio = pd.Series(max_sharpe_weights, index=recommended_stocks)\n",
    "min_var_portfolio = pd.Series(min_var_weights, index=recommended_stocks)\n",
    "risk_parity_portfolio = pd.Series(risk_parity_weights, index=recommended_stocks)\n",
    "\n",
    "# Prune the portfolios using the 'prune_recommended_portfolios' function\n",
    "# This removes assets with negligible weights and renormalizes the remaining weights.\n",
    "max_sharpe_portfolio, min_var_portfolio, risk_parity_portfolio = \\\n",
    "    prune_recommended_portfolios(\n",
    "        max_sharpe_portfolio, min_var_portfolio, risk_parity_portfolio\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate allocations with starting balance\n",
    "balance = 100_000\n",
    "\n",
    "max_sharpe_allocations = max_sharpe_portfolio * balance\n",
    "min_var_allocations = min_var_portfolio * balance\n",
    "risk_parity_allocations = risk_parity_portfolio * balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SHARPE\n",
      "IBM     33241.310395\n",
      "AKAM    27024.379626\n",
      "ORCL    19626.585429\n",
      "NVDA     7406.296679\n",
      "ADBE     4079.603037\n",
      "CRM      3167.185277\n",
      "INTC     2318.406006\n",
      "INTU     1732.935974\n",
      "MSFT     1403.297577\n",
      "dtype: float64\n",
      "\n",
      "MIN_VAR\n",
      "IBM     38405.257609\n",
      "ROP     20519.111493\n",
      "VRSN    13991.314677\n",
      "MSI      6528.583711\n",
      "MSFT     5395.376317\n",
      "AAPL     4203.036844\n",
      "CSCO     4048.467530\n",
      "CRM      3681.360081\n",
      "AKAM     2172.345140\n",
      "CTSH     1055.146599\n",
      "dtype: float64\n",
      "\n",
      "RISK_PARITY\n",
      "MSI     3214.176551\n",
      "IBM     3198.065181\n",
      "ROP     3172.596041\n",
      "VRSN    3086.513404\n",
      "CSCO    2947.525686\n",
      "AKAM    2928.564076\n",
      "AAPL    2749.011148\n",
      "CTSH    2692.799975\n",
      "IT      2624.096986\n",
      "PTC     2620.537527\n",
      "GLW     2602.510294\n",
      "CRM     2590.512095\n",
      "TYL     2558.627617\n",
      "ORCL    2547.879023\n",
      "TDY     2536.458611\n",
      "APH     2458.748296\n",
      "FICO    2429.993574\n",
      "MSFT    2417.584984\n",
      "JNPR    2394.490940\n",
      "NTAP    2322.778446\n",
      "ACN     2304.759617\n",
      "FFIV    2270.361779\n",
      "GEN     2259.109064\n",
      "HPQ     2249.696350\n",
      "TRMB    2017.862442\n",
      "ANSS    1854.984947\n",
      "INTU    1793.795096\n",
      "ADSK    1793.780638\n",
      "DXC     1666.098401\n",
      "SNPS    1656.162468\n",
      "CDNS    1581.914140\n",
      "ADI     1561.614458\n",
      "TXN     1558.766800\n",
      "MU      1473.370658\n",
      "STX     1462.661230\n",
      "INTC    1394.685043\n",
      "QCOM    1380.099109\n",
      "ZBRA    1369.417170\n",
      "WDC     1361.874837\n",
      "AMAT    1349.035841\n",
      "ADBE    1345.358236\n",
      "LRCX    1327.506041\n",
      "SWKS    1307.465919\n",
      "MCHP    1289.459632\n",
      "TER     1272.683096\n",
      "KLAC    1266.683801\n",
      "AMD     1265.391993\n",
      "NVDA    1240.854575\n",
      "ON      1231.076162\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect allocations\n",
    "allocations = [max_sharpe_allocations, min_var_allocations, risk_parity_allocations]\n",
    "portfolios = [\"MAX_SHARPE\", \"MIN_VAR\", \"RISK_PARITY\"]\n",
    "\n",
    "for name, allocation in zip(portfolios, allocations):\n",
    "    print(name)\n",
    "    print(allocation.sort_values(ascending=False))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
